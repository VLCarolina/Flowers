{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VLCarolina/Flowers/blob/main/Flowers_Alexnet_2023.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LUaVnys1Qyuj"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from google.colab import drive\n",
        "from torchsummary import summary"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Mount Google Drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# 2. Load labeled images from folders\n",
        "# data_dir = '/content/gdrive/MyDrive/Data1/antsbeesdataset'\n",
        "data_dir = '/content/gdrive/MyDrive/Data2023/Flowers'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29cc6f4e-f48c-4006-a954-be520b43a876",
        "id": "bZ7O0ihLQyuk"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/gdrive/MyDrive/Data2023/Flowers /"
      ],
      "metadata": {
        "id": "EM6GoyVs4S2c",
        "outputId": "dd60ecbe-38fa-43c1-9e95-c198e6544757",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: '/content/gdrive/MyDrive/Data2023/Flowers /'\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-7Wgp5e4U6H",
        "outputId": "2c15cb8c-128f-422d-802f-271d6c65a597"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mgdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Pre-process the data and create data loaders\n",
        "data_transforms = {\n",
        "    'Train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'Valid': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}"
      ],
      "metadata": {
        "id": "viMy5KEnQyul"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_datasets = {x: datasets.ImageFolder(data_dir + '/' + x, data_transforms[x]) for x in ['Train', 'Valid']}\n",
        "dataloaders = {x: DataLoader(image_datasets[x], batch_size=16, shuffle=True, num_workers=4) for x in ['Train', 'Valid']}\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['Train', 'Valid']}\n",
        "class_names = image_datasets['Train'].classes\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "L5uNetpjQyum",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d3e37eb-7bb8-4e3b-b880-6b70d02573be"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Set up the AlexNet architecture\n",
        "alexnet = models.alexnet(pretrained=True)"
      ],
      "metadata": {
        "id": "4ygsNg7ZQyum",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da06e7ae-2397-4832-c916-7ab217832db7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n",
            "100%|██████████| 233M/233M [00:01<00:00, 236MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "alexnet"
      ],
      "metadata": {
        "id": "oaLKTPxABRwX",
        "outputId": "78cb87a9-8078-48bd-e0c8-ac64964b5851",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AlexNet(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): ReLU(inplace=True)\n",
              "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (9): ReLU(inplace=True)\n",
              "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
              "  (classifier): Sequential(\n",
              "    (0): Dropout(p=0.5, inplace=False)\n",
              "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Dropout(p=0.5, inplace=False)\n",
              "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "num_ftrs = alexnet.classifier[6].in_features\n",
        "alexnet.classifier[6] = nn.Linear(num_ftrs, len(class_names)) # Change last layer\n",
        "alexnet = alexnet.to(device) # Put on GPU"
      ],
      "metadata": {
        "id": "z6-2nk8_BQTr"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alexnet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67bb2fab-042a-4f68-ebc8-72dab1b6666b",
        "id": "lRtUcENjQyun"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AlexNet(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): ReLU(inplace=True)\n",
              "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (9): ReLU(inplace=True)\n",
              "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
              "  (classifier): Sequential(\n",
              "    (0): Dropout(p=0.5, inplace=False)\n",
              "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Dropout(p=0.5, inplace=False)\n",
              "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): Linear(in_features=4096, out_features=30, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary(alexnet, (3, 224, 224))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5d427cb-5398-432f-8e81-89472a2551c4",
        "id": "q5FX_4lxQyuo"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 55, 55]          23,296\n",
            "              ReLU-2           [-1, 64, 55, 55]               0\n",
            "         MaxPool2d-3           [-1, 64, 27, 27]               0\n",
            "            Conv2d-4          [-1, 192, 27, 27]         307,392\n",
            "              ReLU-5          [-1, 192, 27, 27]               0\n",
            "         MaxPool2d-6          [-1, 192, 13, 13]               0\n",
            "            Conv2d-7          [-1, 384, 13, 13]         663,936\n",
            "              ReLU-8          [-1, 384, 13, 13]               0\n",
            "            Conv2d-9          [-1, 256, 13, 13]         884,992\n",
            "             ReLU-10          [-1, 256, 13, 13]               0\n",
            "           Conv2d-11          [-1, 256, 13, 13]         590,080\n",
            "             ReLU-12          [-1, 256, 13, 13]               0\n",
            "        MaxPool2d-13            [-1, 256, 6, 6]               0\n",
            "AdaptiveAvgPool2d-14            [-1, 256, 6, 6]               0\n",
            "          Dropout-15                 [-1, 9216]               0\n",
            "           Linear-16                 [-1, 4096]      37,752,832\n",
            "             ReLU-17                 [-1, 4096]               0\n",
            "          Dropout-18                 [-1, 4096]               0\n",
            "           Linear-19                 [-1, 4096]      16,781,312\n",
            "             ReLU-20                 [-1, 4096]               0\n",
            "           Linear-21                   [-1, 30]         122,910\n",
            "================================================================\n",
            "Total params: 57,126,750\n",
            "Trainable params: 57,126,750\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 8.37\n",
            "Params size (MB): 217.92\n",
            "Estimated Total Size (MB): 226.87\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3538b0a9-76cf-4650-8968-197f077a581a",
        "id": "37A0yA73Qyuo"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['1',\n",
              " '10',\n",
              " '11',\n",
              " '12',\n",
              " '13',\n",
              " '14',\n",
              " '15',\n",
              " '16',\n",
              " '17',\n",
              " '18',\n",
              " '19',\n",
              " '2',\n",
              " '20',\n",
              " '21',\n",
              " '22',\n",
              " '23',\n",
              " '24',\n",
              " '25',\n",
              " '26',\n",
              " '27',\n",
              " '28',\n",
              " '29',\n",
              " '3',\n",
              " '30',\n",
              " '4',\n",
              " '5',\n",
              " '6',\n",
              " '7',\n",
              " '8',\n",
              " '9']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_sizes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87f77431-99b5-4399-8e50-02d1880d0395",
        "id": "o-V0ud6kQyup"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Train': 125, 'Valid': 34}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for inputs, labels in dataloaders[\"Train\"]:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)"
      ],
      "metadata": {
        "id": "wY4aR1Mc5jKc"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFR9SGTO5kl3",
        "outputId": "26604107-c567-49d2-fe20-cc258c8da032"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([13, 3, 224, 224])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvht0nWV5wdR",
        "outputId": "02158141-aebe-42a3-f482-7132480107af"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([13])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-6DBNL45yFr",
        "outputId": "b9cf2c91-59ad-425b-c9f1-bb13e22462e3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([16,  1, 20, 23, 11, 11,  7, 27, 28, 23, 24, 14, 19], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = alexnet(inputs)"
      ],
      "metadata": {
        "id": "Jroxm1Nq57kE"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ns23X5bt5-TO",
        "outputId": "8687f867-ac71-407f-dc04-db452d81c86c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([13, 30])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUmgmT_o6Si9",
        "outputId": "846b7961-350a-4311-c880-89367c3cb4bb"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.1063,  0.0806, -0.2002,  0.2300,  0.4307,  0.2919, -0.5901, -1.0930,\n",
              "          0.0164,  1.1225,  1.0919, -0.3575,  0.1014,  0.7508,  0.6840,  0.7922,\n",
              "         -0.2078, -0.3326,  1.5976,  0.0222,  0.2853, -0.7379,  0.3903,  0.0478,\n",
              "         -0.0617,  0.2313,  0.6261, -0.8001,  0.0186,  1.1181],\n",
              "        [ 0.5188, -0.2837, -0.0815, -0.5249, -0.2455, -0.4923, -0.4099,  0.8123,\n",
              "         -0.4956,  0.2667,  0.5897,  0.6549,  0.9006, -0.1941,  0.4036,  0.1499,\n",
              "          0.3228, -0.3753,  0.8236, -0.3276, -0.5814,  0.0745, -0.2366, -0.1734,\n",
              "          0.5259,  0.0801, -0.0950,  0.4672,  0.4342, -0.1169],\n",
              "        [ 1.1007, -0.2889, -0.0266, -0.1986, -0.2133,  0.2631, -0.1012,  0.0138,\n",
              "          0.3915,  0.9309, -0.0243,  0.3354, -0.1993,  0.8798, -1.1821, -1.0113,\n",
              "          1.0864, -0.0711,  0.6508,  0.0377, -0.8748, -0.3824,  0.1558,  0.0226,\n",
              "          0.7552, -0.5756, -0.6829, -1.2185,  0.3068,  0.3403],\n",
              "        [-0.5896,  0.7381,  0.2159,  0.2786,  0.2851,  2.6034, -0.5384, -0.6959,\n",
              "          1.6214, -1.2370,  1.1243, -0.9454, -0.0890,  0.3761,  0.4511, -0.8039,\n",
              "          0.2632, -0.1769,  0.7311, -0.6198,  0.7217, -1.4070, -0.6134,  0.6434,\n",
              "         -1.6083, -0.0076,  2.0318, -0.2165, -0.3356,  1.6543],\n",
              "        [ 0.7453,  1.1737,  0.0533, -1.2868, -0.3446, -0.3927, -0.8406,  1.2419,\n",
              "          0.4613,  0.4103,  0.0313, -0.7035, -0.4467,  0.4804, -0.2525, -1.0600,\n",
              "          0.5775, -0.2988,  1.4664,  0.5116, -0.1209,  0.0843, -0.9356,  0.4387,\n",
              "         -0.2392,  0.6747, -0.3751,  0.8239, -0.3661, -0.4445],\n",
              "        [ 0.9460,  0.5131, -0.9637, -1.6452, -0.7365, -0.4509, -0.1393,  0.5596,\n",
              "         -0.1568,  0.1093,  0.6844, -1.2207, -0.7162, -0.0247,  0.0613, -0.3726,\n",
              "          0.8337, -0.4083,  1.2598,  0.3241,  0.1196, -1.2838, -1.0906, -0.0995,\n",
              "         -0.1340,  0.6189, -0.2059,  0.6232, -0.2996, -1.0608],\n",
              "        [ 1.3606, -0.0909, -0.3986, -0.7879, -0.8721, -0.4450, -0.9078,  0.2643,\n",
              "         -0.8351, -0.6272,  0.4119, -0.0706, -0.0113, -0.1126, -0.1695, -0.2042,\n",
              "          0.9973, -0.1441,  1.3209, -1.0500, -0.6113, -0.6969,  0.8875,  0.6697,\n",
              "         -1.4977, -0.7677,  0.1492, -0.7402, -0.6499,  0.3701],\n",
              "        [ 1.0203, -0.4073,  0.3193, -0.5554, -1.2490, -0.2643, -0.0107,  0.8759,\n",
              "         -0.4960,  0.3467,  0.0829,  0.6728,  0.2725, -0.9774,  0.2695, -0.6470,\n",
              "          1.2583, -0.5718,  0.9815, -0.3312, -0.3525, -0.1173, -0.5390,  0.5636,\n",
              "          0.2802, -0.8042,  0.7951,  0.2544, -0.0047, -0.5704],\n",
              "        [ 2.3216,  0.5368, -1.8868, -0.6252, -0.5419,  0.4350,  0.0876,  0.7933,\n",
              "          0.5339, -0.4752, -0.2016,  0.5139,  0.0151,  1.4164,  0.0284, -0.8591,\n",
              "          1.6571, -0.8898,  0.6812, -1.0762, -0.6016, -0.6648, -1.1251, -0.9785,\n",
              "         -0.9039, -0.6114, -1.0364, -0.7741, -0.4365,  0.6524],\n",
              "        [-0.1919,  0.0619, -0.9270, -0.6222, -0.3707,  1.7181, -0.0859, -0.5647,\n",
              "          0.9441,  0.4883,  0.3496, -0.3977, -0.1402,  0.6525,  0.2903, -0.4372,\n",
              "          0.5976,  0.1636,  0.8032, -0.0969,  0.6747, -1.8227, -1.0348, -0.5043,\n",
              "         -0.6901, -0.8493,  0.9550, -0.7824, -1.1702,  1.0806],\n",
              "        [ 0.7098,  0.2105,  0.3535, -0.6389, -0.6077,  0.3106, -0.4461,  1.2508,\n",
              "          0.1952, -0.2771, -0.2346,  0.1173,  0.7554, -0.1893,  0.2015, -0.2091,\n",
              "          1.1105, -0.7690,  1.1575, -0.2192, -0.1900, -0.4606, -0.6829,  1.1291,\n",
              "          0.0637, -0.2897,  0.2413,  0.3919, -0.3395, -0.3133],\n",
              "        [ 0.6657, -0.8941, -0.7475, -0.2320,  0.8104,  0.7166,  1.4351,  0.5815,\n",
              "         -0.3867,  0.9023,  0.3527,  0.4090, -0.0385,  0.8865,  0.8068, -0.3660,\n",
              "         -0.2345, -0.0392,  0.6701,  0.4142, -0.5029, -0.1506, -0.2353, -0.8507,\n",
              "         -0.6119,  0.4123, -0.8500,  0.8909, -0.2096,  0.3588],\n",
              "        [ 0.9936,  0.3413, -0.2495,  0.0949,  0.1155,  0.1225,  0.8613,  1.0805,\n",
              "         -0.3904,  0.2514, -0.5757, -0.0953,  0.4673, -0.4338,  1.0014, -0.5720,\n",
              "         -0.0875, -0.1424, -0.0064,  0.2134,  0.0268, -1.0869,  0.1077,  0.3163,\n",
              "         -0.4808,  0.5190, -0.4499, -0.4307, -0.2184,  0.1483]],\n",
              "       device='cuda:0', grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.max(outputs,1)[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYKwy0V26lrZ",
        "outputId": "e2d354bc-832d-49bc-98b0-1b687ce4ea88"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.5976, 0.9006, 1.1007, 2.6034, 1.4664, 1.2598, 1.3606, 1.2583, 2.3216,\n",
              "        1.7181, 1.2508, 1.4351, 1.0805], device='cuda:0',\n",
              "       grad_fn=<MaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.max(outputs,1)[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EvUQpF4X7GJE",
        "outputId": "0da80219-5bbd-43df-9a0a-6124e100cf16"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([18, 12,  0,  5, 18, 18,  0, 16,  0,  5,  7,  6,  7], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds = torch.max(outputs, 1)[1]"
      ],
      "metadata": {
        "id": "H69nOoKv6hTR"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCmjTq2Y7OLZ",
        "outputId": "c45f945e-3734-47ba-d154-30bf7b503d85"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([18, 12,  0,  5, 18, 18,  0, 16,  0,  5,  7,  6,  7], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2QI-brXn7QmJ",
        "outputId": "0b091112-3c17-4bc8-9669-e17bb9c577f9"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([16,  1, 20, 23, 11, 11,  7, 27, 28, 23, 24, 14, 19], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds == labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dpFhgbR7VSt",
        "outputId": "9f130f37-9ddb-4cb7-9dd1-ed38fbd162a2"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([False, False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels.shape[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IgfPIPIJ7hz_",
        "outputId": "46acfe41-023d-4ac0-b472-3c07deb727b8"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.sum(preds == labels)/labels.shape[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVSMVojH7ZGD",
        "outputId": "84d21b95-0dd9-4715-effe-ea94ed3c5bd8"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0., device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(alexnet.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Train the AlexNet model\n",
        "alexnet.train()\n",
        "\n",
        "num_epochs = 20\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(epoch, \" of \", num_epochs - 1)\n",
        "    print('-' * 10)\n",
        "\n",
        "    running_corrects = 0\n",
        "\n",
        "    for inputs, labels in dataloaders[\"Train\"]:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        \n",
        "\n",
        "        outputs = alexnet(inputs)\n",
        "        preds = torch.max(outputs, 1)[1]\n",
        "\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "    print('Train Acc: {:.4f}'.format(running_corrects / dataset_sizes[\"Train\"]))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Evaluate the AlexNet model on Validation Data\n",
        "    alexnet.eval()\n",
        "\n",
        "    running_corrects = 0\n",
        "\n",
        "    for inputs, labels in dataloaders[\"Valid\"]:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "\n",
        "        outputs = alexnet(inputs)\n",
        "        preds = torch.max(outputs, 1)[1]\n",
        "\n",
        "\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "    acc_valid = running_corrects / dataset_sizes[\"Valid\"]\n",
        "    print('Valid Acc: {:.4f}'.format(acc_valid))\n",
        "    if acc_valid > 0.99:\n",
        "        print(\"Done!\")\n",
        "        break\n",
        "\n",
        "\n",
        "print('Training complete')"
      ],
      "metadata": {
        "id": "BsdI_Z1vM7VM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66f4d614-f60e-4166-ad62-ad6a1e53ecce"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0  of  19\n",
            "----------\n",
            "Train Acc: 0.0880\n",
            "Valid Acc: 0.5294\n",
            "1  of  19\n",
            "----------\n",
            "Train Acc: 0.6000\n",
            "Valid Acc: 0.8824\n",
            "2  of  19\n",
            "----------\n",
            "Train Acc: 0.9200\n",
            "Valid Acc: 0.8824\n",
            "3  of  19\n",
            "----------\n",
            "Train Acc: 0.8400\n",
            "Valid Acc: 0.9118\n",
            "4  of  19\n",
            "----------\n",
            "Train Acc: 0.9040\n",
            "Valid Acc: 0.9412\n",
            "5  of  19\n",
            "----------\n",
            "Train Acc: 0.9120\n",
            "Valid Acc: 1.0000\n",
            "Done!\n",
            "Training complete\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "SCVeSlOF-CjA",
        "outputId": "9ba43f03-0754-4393-a387-253cff6809f7"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = '/content/gdrive/MyDrive/Data2023/SmartTrashCan/alexnet_classification_SmartTrashCan.pth'"
      ],
      "metadata": {
        "id": "zmhjefa5QdSu"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained model\n",
        "torch.save(alexnet.state_dict(), model_path)"
      ],
      "metadata": {
        "id": "dBlJWh3QQyur"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r73P4wWv-Qj5",
        "outputId": "27701bc5-3d09-4b66-c2f1-16968d110cfd"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mgdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "\n",
        "# 1. Load the trained AlexNet model\n",
        "def load_model(model_path):\n",
        "    model = models.alexnet()\n",
        "    num_ftrs = model.classifier[6].in_features\n",
        "    model.classifier[6] = nn.Linear(num_ftrs, len(class_names))\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "    model.eval()\n",
        "    return model.to(device)\n",
        "\n",
        "# 2. Define a function to load an image from a URL and preprocess it\n",
        "def preprocess_image(url, transform):\n",
        "    response = requests.get(url)\n",
        "    img = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
        "    img_tensor = transform(img)\n",
        "    return img_tensor.unsqueeze(0).to(device)\n",
        "\n",
        "# 3. Perform inference using the loaded model\n",
        "def predict_image_url(url, model):\n",
        "    img_tensor = preprocess_image(url, data_transforms['Valid'])\n",
        "    output = model(img_tensor)\n",
        "    pred = torch.max(output, 1)[1]\n",
        "    return class_names[pred]"
      ],
      "metadata": {
        "id": "6owtKjwZQyus"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trained_model = load_model(model_path)"
      ],
      "metadata": {
        "id": "a51GZ4wW-4yw"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_url = 'https://agrogojarviveros.com/entradavivero/uploads/2018/08/orqu%C3%ADdea.jpg'"
      ],
      "metadata": {
        "id": "HxRmKBwQQyut"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = predict_image_url(image_url, trained_model)"
      ],
      "metadata": {
        "id": "8fTxsPSoSi6S"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The predicted class for the input image is:\", prediction)"
      ],
      "metadata": {
        "id": "EwBsL__ySiKa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f42bbb9d-a6ac-4b6a-bf51-ea2542fc9be9"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The predicted class for the input image is: 25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nxl5kNk5Qyut"
      },
      "execution_count": 38,
      "outputs": []
    }
  ]
}